# Walkthrough

> A detailed step-by-step cookbook of the core features provided by R2R.

This guide shows how to use R2R to:

1. Ingest files into R2R
2. Search over ingested files
3. Use your data as input to RAG (Retrieval-Augmented Generation) / Deep Research
4. Extract entities and relationships from your data to create a graph.
5. Perform basic user auth
6. Observe and analyze an R2R deployment

## Introduction

R2R is an engine for building user-facing Retrieval-Augmented Generation (RAG) applications. At its core, R2R provides this service through an architecture of providers, services, and a centralized RESTful API. This cookbook provides a detailed walkthrough of how to interact with R2R.

[Refer here](/introduction/system) for a deeper dive on the R2R system architecture.

## Hello R2R

R2R gives developers configurable vector search and RAG right out of the box, as well as direct method calls instead of the client-server architecture seen throughout the docs:

```python core/examples/hello_r2r.py
from r2r import R2RClient

client = R2RClient() # optional, pass in "http://localhost:7272" or "https://api.sciphi.ai"

with open("test.txt", "w") as file:
    file.write("John is a person that works at Google.")

client.documents.create(file_path="test.txt")

# Call RAG directly
rag_response = client.retrieval.rag(
    query="Who is john",
    rag_generation_config={"model": "openai/gpt-4o-mini", "temperature": 0.0},
)

print(f"Search Results:\n{rag_response.results.search_results}")
# AggregateSearchResult(chunk_search_results=[ChunkSearchResult(score=0.685, text=John is a person that works at Google.)], graph_search_results=[], web_search_results=[], context_document_results=[])

print(f"Completion:\n{rag_response.results.generated_answer}")
# John is a person that works at Google [e123456].

print(f"Citations:\n{rag_response.results.citations}")
# [Citation(id='e123456', object='citation', payload=ChunkSearchResult(...))]
```

## Document Ingestion and Management

R2R efficiently handles diverse document types using Postgres with pgvector, combining relational data management with vector search capabilities. This approach enables seamless ingestion, storage, and retrieval of multimodal data, while supporting flexible document management and user permissions.

Key features include:

* Unique [`Document`](/api-and-sdks/documents/documents), with corresponding `id`, created for each ingested file or context, which contains the downstream [`Chunks`](/api-and-sdks/chunks/chunks) and [`Entities` & `Relationships`](/api-and-sdks/graphs/graphs).
* [`User`](/api-and-sdks/users/users) and [`Collection`](/api-and-sdks/collections/collections) objects for comprehensive document permissions.
* [`Graph`](/api-and-sdks/graphs/graphs), construction and maintenance.
* Flexible document deletion and update mechanisms at global document and chunk levels.

<Note>
   Note, all document related commands are gated to documents the user has uploaded or has access to through shared collections, with the exception of superusers. 
</Note>

<AccordionGroup>
  <Accordion icon="database" title="Create Documents" defaultOpen={true}>
    R2R offers a powerful data ingestion process that handles various file types including `html`, `pdf`, `png`, `mp3`, and `txt`.

    The ingestion process parses, chunks, embeds, and stores documents efficiently. A durable orchestration workflow coordinates the entire process.

    <Tabs>
      <Tab title="Python">
        ```python
        # export R2R_API_KEY=...
        from r2r import R2RClient

        client = R2RClient() # or set base_url=...
        # when using auth, do client.users.login(...)

        client.documents.create_sample(hi_res=True)
        # to ingest your own document, client.documents.create(file_path="/path/to/file")
        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        // export R2R_API_KEY=...
        const { r2rClient } = require('r2r-js');

        const client = new r2rClient(); // or set baseURL=...

        clients.documents.createSample({ ingestionMode: "hi-res" })
        // to ingest your own document, client.documents.create({filePath: </path/to/file>})
        ```
      </Tab>
    </Tabs>

    This command initiates the ingestion process, producing output similar to:

    ```plaintext
    IngestionResponse(message='Document created and ingested successfully.', task_id=None, document_id=UUID('e43864f5-a36f-548e-aacd-6f8d48b30c7f'))
    ```

    Key features of the ingestion process:

    1. Unique `document_id` generation for each file
    2. Metadata association, including `user_id` and `collection_ids` for document management
    3. Efficient parsing, chunking, and embedding of diverse file types
  </Accordion>

  <Accordion icon="folder-open" title="Retrieving Documents">
    R2R allows retrieval of high-level document information stored in a relational table within the Postgres database. To fetch this information:

    <Tabs>
      <Tab title="Python">
        ```python
        result = client.documents.list(
            limit=10,
            offset=0
        )
        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        const response = await client.documents.list({
            limit: 10,
            offset: 0,
        });
        ```
      </Tab>

      <Tab title="Curl">
        ```zsh
        curl -X GET https://api.sciphi.ai/v3/documents \
          -H "Content-Type: application/json" \
          -H "Authorization: Bearer your_token_here"
        ```
      </Tab>
    </Tabs>

    This command returns document metadata, including:

    ```plaintext
    [
      DocumentResponse(
        id=UUID('e43864f5-a36f-548e-aacd-6f8d48b30c7f'), 
        collection_ids=[UUID('122fdf6a-e116-546b-a8f6-e4cb2e2c0a09')], 
        owner_id=UUID('2acb499e-8428-543b-bd85-0d9098718220'), 
        document_type=<DocumentType.PDF: 'pdf'>, 
        metadata={'title': 'DeepSeek_R1.pdf', 'version': 'v0'}, 
        version='v0', 
        size_in_bytes=1768572, 
        ingestion_status=<IngestionStatus.SUCCESS: 'success'>, 
        extraction_status=<GraphExtractionStatus.PENDING: 'pending'>, 
        created_at=datetime.datetime(2025, 2, 8, 3, 31, 39, 126759, tzinfo=TzInfo(UTC)), 
        updated_at=datetime.datetime(2025, 2, 8, 3, 31, 39, 160114, tzinfo=TzInfo(UTC)), 
        ingestion_attempt_number=None, 
        summary="The document contains a comprehensive overview of DeepSeek-R1, a series of reasoning models developed by DeepSeek-AI, which includes DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero utilizes large-scale reinforcement learning (RL) without supervised fine-tuning, showcasing impressive reasoning capabilities but facing challenges like readability and language mixing. To enhance performance, DeepSeek-R1 incorporates multi-stage training and cold-start data, achieving results comparable to OpenAI's models on various reasoning tasks. The document details the models' training processes, evaluation results across multiple benchmarks, and the introduction of distilled models that maintain reasoning capabilities while being smaller and more efficient. It also discusses the limitations of current models, such as language mixing and sensitivity to prompts, and outlines future research directions to improve general capabilities and efficiency in software engineering tasks. The findings emphasize the potential of RL in developing reasoning abilities in large language models and the effectiveness of distillation techniques for smaller models.", summary_embedding=None, total_tokens=29673)] total_entries=1
      ), ...
    ]
    ```

    This overview provides quick access to document versions, sizes, and associated metadata, facilitating efficient document management.
  </Accordion>

  <Accordion icon="file" title="Retrieving Document Chunks">
    R2R enables retrieval of specific document chunks and associated metadata. To fetch chunks for a particular document by id:

    <Tabs>
      <Tab title="Python">
        ```python
        client.documents.list_chunks(id="9fbe403b-c11c-5aae-8ade-ef22980c3ad1")
        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        await client.documents.listChunks({
          id: "9fbe403b-c11c-5aae-8ade-ef22980c3ad1",
        }),
        ```
      </Tab>

      <Tab title="Curl">
        ```zsh
        curl -X GET https://api.sciphi.ai/v3/documents/9fbe403b-c11c-5aae-8ade-ef22980c3ad1/chunks \
          -H "Content-Type: application/json" \
          -H "Authorization: Bearer your_token_here"
        ```
      </Tab>
    </Tabs>

    This command returns detailed chunk information:

    ```plaintext
    results=[ChunkResponse(id=UUID('27a2e605-2916-59fe-a4da-b19853713298'), document_id=UUID('30f950f0-c692-57c5-b6ec-ff78ccf5ccdc'), owner_id=UUID('2acb499e-8428-543b-bd85-0d9098718220'), collection_ids=[UUID('122fdf6a-e116-546b-a8f6-e4cb2e2c0a09')], text='John is a person that works at Google.', metadata={'version': 'v0', 'chunk_order': 0, 'document_type': 'txt'}, vector=None)] total_entries=1
    ```

    These features allow for granular access to document content.
  </Accordion>

  <Accordion icon="trash" title="Deleting Documents">
    R2R supports flexible document deletion through a method that can run arbitrary deletion filters. To delete a document by its ID:

    <Tabs>
      <Tab title="Python">
        ```python
        client.documents.delete(id="9fbe403b-c11c-5aae-8ade-ef22980c3ad1")
        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        await client.documents.delete({
          id: "9fbe403b-c11c-5aae-8ade-ef22980c3ad1",
        });
        ```
      </Tab>

      <Tab title="Curl">
        ```zsh
        curl -X DELETE https://api.sciphi.ai/v3/documents/9fbe403b-c11c-5aae-8ade-ef22980c3ad1 \
          -H "Content-Type: application/json" \
          -H "Authorization: Bearer your_token_here"
        ```
      </Tab>
    </Tabs>

    This command produces output similar to:

    ```plaintext
    GenericBooleanResponse(success=True)
    ```

    Key features of the deletion process:

    1. Deletion by document ID,
    2. Cascading deletion of associated chunks and metadata
    3. Deletion by filter, e.g. by text match, user id match, or other with `documents/by-filter`.

    This flexible deletion mechanism ensures precise control over document management within the R2R system.
  </Accordion>
</AccordionGroup>

For more advanced document management techniques and user authentication details, refer to [the user documentation](/documentation/user-auth).

## AI Powered Search

R2R offers powerful and highly configurable search capabilities, including vector search, hybrid search, and knowledge graph-enhanced search. These features allow for more accurate and contextually relevant information retrieval.

### Vector Search

Vector search parameters inside of R2R can be fine-tuned at runtime for optimal results. Here's how to perform a basic vector search:

<Tabs>
  <Tab title="Python">
    ```python
    client.retrieval.search(
      query="What is DeepSeek R1?",
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```javascript
    client.retrieval.search({
      query: "What is DeepSeek R1?",
    })
    ```
  </Tab>

  <Tab title="Curl">
    ```zsh
    curl -X POST https://api.sciphi.ai/v3/retrieval/search \
      -H "Content-Type: application/json" \
      -d '{
        "query": "What is DeepSeek R1?"
      }' \
      -H "Authorization: Bearer your_token_here"
    ```
  </Tab>
</Tabs>

<AccordionGroup>
  <Accordion title="Expected Output">
    ```plaintext
    AggregateSearchResult(
      chunk_search_results=[
        ChunkSearchResult(
          score=0.643, 
          text="Document Title: DeepSeek_R1.pdf
          Text: could achieve an accuracy of over 70%.
          DeepSeek-R1 also delivers impressive results on IF-Eval, a benchmark designed to assess a
          models ability to follow format instructions. These improvements can be linked to the inclusion
          of instruction-following data during the final stages of supervised fine-tuning (SFT) and RL
          training. Furthermore, remarkable performance is observed on AlpacaEval2.0 and ArenaHard,
          indicating DeepSeek-R1s strengths in writing tasks and open-domain question answering. Its
          significant outperformance of DeepSeek-V3 underscores the generalization benefits of large-scale
          RL, which not only boosts reasoning capabilities but also improves performance across diverse
          domains. Moreover, the summary lengths generated by DeepSeek-R1 are concise, with an
          average of 689 tokens on ArenaHard and 2,218 characters on AlpacaEval 2.0. This indicates that
          DeepSeek-R1 avoids introducing length bias during GPT-based evaluations, further solidifying
          its robustness across multiple tasks."
        ), ...
      ],
      graph_search_results=[],
      web_search_results=[],
      context_document_results=[]
    )
    ```
  </Accordion>
</AccordionGroup>

Key configurable parameters for vector search can be inferred from the [retrieval API reference](/api-and-sdks/retrieval/retrieval).

### Hybrid Search

R2R supports hybrid search, which combines traditional keyword-based search with vector search for improved results. Here's how to perform a hybrid search:

<Tabs>
  <Tab title="Python">
    ```python
    client.retrieval.search(
        "What was Uber's profit in 2020?",
        search_settings={
            "index_measure": "l2_distance",
            "use_hybrid_search": True,
            "hybrid_settings": {
                "full_text_weight": 1.0,
                "semantic_weight": 5.0,
                "full_text_limit": 200,
                "rrf_k": 50,
            }
        },
    )
    ```
  </Tab>

  <Tab title="JavaScript">
    ```javascript
    await client.retrieval.search({
      query: "What was Uber's profit in 2020? ",
      searchSettings: {
        indexMeasure: "l2_distance",
        useHybridSearch: true,
        hybridSettings: {
            fullTextWeight: 1.0,
            semanticWeight: 5.0,
            fullTextLimit: 200,
        },
        filters: {"title": {"$in": ["DeepSeek_R1.pdf"]}},
      },
    });
    ```
  </Tab>

  <Tab title="Curl">
    ```zsh
    curl -X POST https://api.sciphi.ai/v3/retrieval/search \
      -H "Content-Type: application/json" \
      -d '{
        "query": "What was Uber'\''s profit in 2020?",
        "search_settings": {
          "use_hybrid_search": true,
          "hybrid_settings": {
            "full_text_weight": 1.0,
            "semantic_weight": 5.0,
            "full_text_limit": 200,
            "rrf_k": 50
          },
          "filters": {"title": {"$in": ["DeepSeek_R1.pdf", "uber_2021.pdf"]}},
          "limit": 10,
          "chunk_settings": {
            "index_measure": "l2_distance",
            "probes": 25,
            "ef_search": 100
          }      
        }
      }' \
      -H "Authorization: Bearer your_token_here"
    ```
  </Tab>
</Tabs>

## AI Retrieval (RAG)

R2R is built around a comprehensive Retrieval-Augmented Generation (RAG) engine, allowing you to generate contextually relevant responses based on your ingested documents. The RAG process combines all the search functionality shown above with Large Language Models to produce more accurate and informative answers.

<AccordionGroup>
  <Accordion icon="brain" title="Basic RAG" defaultOpen={true}>
    To generate a response using RAG, use the following command:

    <Tabs>
      <Tab title="Python">
        ```python
        client.retrieval.rag(query="What is DeepSeek R1?")
        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        await client.rag({ query: "What is DeepSeek R1?" });
        ```
      </Tab>

      <Tab title="Curl">
        ```zsh
        curl -X POST https://api.sciphi.ai/v3/retrieval/rag \
          -H "Content-Type: application/json" \
          -d '{
            "query": "What is DeepSeek R1?"
          }' \
          -H "Authorization: Bearer your_token_here"
        ```
      </Tab>
    </Tabs>

    **Example Output:**

    ```zsh
    RAGResponse(
        generated_answer='DeepSeek-R1 is a model that demonstrates impressive performance across various tasks, leveraging reinforcement learning (RL) and supervised fine-tuning (SFT) to enhance its capabilities. It excels in writing tasks, open-domain question answering, and benchmarks like IF-Eval, AlpacaEval2.0, and ArenaHard [1], [2]. DeepSeek-R1 outperforms its predecessor, DeepSeek-V3, in several areas, showcasing its strengths in reasoning and generalization across diverse domains [1]. It also achieves competitive results on factual benchmarks like SimpleQA, although it performs worse on the Chinese SimpleQA benchmark due to safety RL constraints [2]. Additionally, DeepSeek-R1 is involved in distillation processes to transfer its reasoning capabilities to smaller models, which perform exceptionally well on benchmarks [4], [6]. The model is optimized for English and Chinese, with plans to address language mixing issues in future updates [8].', 
        search_results=AggregateSearchResult(
          chunk_search_results=[ChunkSearchResult(score=0.643, text='Document Title: DeepSeek_R1.pdf...')]
        ),
        citations=[
          Citation(
            id='123456', 
            object='citation', 
            payload=ChunkSearchResult(score=0.643, text='Document Title: DeepSeek_R1.pdf...', id='e760bb76-1c6e-52eb-910d-0ce5b567011b', document_id='e43864f5-a36f-548e-aacd-6f8d48b30c7f', owner_id='2acb499e-8428-543b-bd85-0d9098718220', collection_ids=['122fdf6a-e116-546b-a8f6-e4cb2e2c0a09'])
          )
        ],
        metadata={'id': 'chatcmpl-B0BaZ0vwIa58deI0k8NIuH6pBhngw', 'choices': [...], 'created': 1739384247, 'model': 'gpt-4o-2024-08-06', ...}
    )
    ```

    This command performs a search on the ingested documents and uses the retrieved information to generate a response.
  </Accordion>

  <Accordion icon="layer-group" title="RAG w/ Hybrid Search">
    R2R also supports hybrid search in RAG, combining the power of vector search and keyword-based search. To use hybrid search in RAG, simply add the `use_hybrid_search` flag to your search settings input:

    <Tabs>
      <Tab title="Python">
        ```javascript
        results = client.retrieval.rag("Who is Jon Snow?", {"use_hybrid_search": True})
        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        await client.rag({
          query: "Who is Jon Snow?",
          searchSettings: {
            useHybridSearch: true
          },
        });
        ```
      </Tab>

      <Tab title="Curl">
        ```zsh
        curl -X POST https://api.sciphi.ai/v3/retrieval/rag \
          -H "Content-Type: application/json" \
          -d '{
            "query": "Who is Jon Snow?",
            "chunk_settings": {
              "use_semantic_search": true,
              "filters": {},
              "limit": 10,
              "use_hybrid_search": true
            }
          }' \
          -H "Authorization: Bearer your_token_here"
        ```
      </Tab>
    </Tabs>

    This example demonstrates how hybrid search can enhance the RAG process by combining semantic understanding with keyword matching, potentially providing more accurate and comprehensive results.
  </Accordion>

  <Accordion icon="screencast" title="Streaming RAG">
    R2R also supports streaming RAG responses, which can be useful for real-time applications.

    When using streaming RAG, you'll receive different types of events:

    1. `SearchResultsEvent` - Contains the initial search results from your documents
    2. `MessageEvent` - Streams partial tokens of the response as they are generated
    3. `CitationEvent` - Indicates when a citation is added to the response, with relevant metadata including:
       * `id` - Unique identifier for the citation
       * `object` - Always "citation"
       * `source_type` - The type of source (chunk, graph, web, etc.)
       * `source_title` - Title of the source document when available
    4. `FinalAnswerEvent` - Contains the complete generated answer and structured citations
    5. `ThinkingEvent` - For reasoning agents, contains the model's step-by-step reasoning process

    The citations in the final response are structured objects that link specific passages in the response to their source documents, enabling proper attribution and verification. To use streaming RAG:

    Generate a streaming RAG response:

    <Tabs>
      <Tab title="Python">
        ```python
        from r2r import (
            CitationEvent,
            FinalAnswerEvent,
            MessageEvent,
            SearchResultsEvent,
            R2RClient,
        )


        result_stream = client.retrieval.rag(
            query="What is DeepSeek R1?",
            search_settings={"limit": 25},
            rag_generation_config={"stream": True},
        )

        # can also do a switch on `type` field
        for event in result_stream:
            if isinstance(event, SearchResultsEvent):
                print("Search results:", event.data)
            elif isinstance(event, MessageEvent):
                print("Partial message:", event.data.delta)
            elif isinstance(event, CitationEvent):
                print("New citation detected:", event.data)
            elif isinstance(event, FinalAnswerEvent):
                print("Final answer:", event.data.generated_answer)
        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        // 1) Initiate a streaming RAG request
        const resultStream = await client.retrieval.rag({
        query: "What is DeepSeek R1?",
        searchSettings: { limit: 25 },
        ragGenerationConfig: { stream: true },
        });

        // 2) Check if we got an async iterator (streaming)
        if (Symbol.asyncIterator in resultStream) {
        // 2a) Loop over each event from the server
        for await (const event of resultStream) {
            switch (event.event) {
            case "search_results":
                console.log("Search results:", event.data);
                break;
            case "message":
                console.log("Partial message delta:", event.data.delta);
                break;
            case "citation":
                console.log("New citation event:", event.data);
                break;
            case "final_answer":
                console.log("Final answer:", event.data.generated_answer);
                break;
            // ... add more cases if you have other event types, e.g. tool_call / tool_result
            default:
                console.log("Unknown or unhandled event:", event);
            }
        }
        } else {
        // 2b) If streaming was NOT enabled or server didn't send SSE,
        //     we'd get a single response object instead.
        console.log("Non-streaming RAG response:", resultStream);
        }
        ```
      </Tab>

      <Tab title="Curl">
        ```bash
        ...
        ```
      </Tab>
    </Tabs>

    Example output:

    ```plaintext
    Search results: id='run_1' object='rag.search_results' data={'chunk_search_results': [{'id': '1e40ee7e-2eef-524f-b5c6-1a1910e73ccc', 'document_id': '652075c0-3a43-519f-9625-f581e7605bc5', 'owner_id': '2acb499e-8428-543b-bd85-0d9098718220', 'collection_ids': ['122fdf6a-e116-546b-a8f6-e4cb2e2c0a09'], 'score': 0.7945216641038179, 'text': 'data, achieving strong performance across various tasks. DeepSeek-R1 is more powerful,\nleveraging cold-start data alongside iterative RL fine-tuning. Ultimately ... 
    ...
    Partial message: {'content': [MessageDelta(type='text', text={'value': 'Deep', 'annotations': []})]}
    Partial message: {'content': [MessageDelta(type='text', text={'value': 'Seek', 'annotations': []})]}
    Partial message: {'content': [MessageDelta(type='text', text={'value': '-R', 'annotations': []})]}
    ...
    New Citation Detected: 'cit_3a35e39'
    ...
    Final answer: DeepSeek-R1 is a large language model developed by the DeepSeek-AI research team. It is a reasoning model that has been trained using multi-stage training and cold-start data before reinforcement learning (RL). The model demonstrates superior performance on various benchmarks, including MMLU, MMLU-Pro, GPQA Diamond, and FRAMES, particularly in STEM-related questions. ...
    ```

    Streaming allows the response to be generated and sent in real-time, chunk by chunk.
  </Accordion>

  <Accordion icon="gears" title="Customizing RAG">
    R2R offers extensive customization options for its Retrieval-Augmented Generation (RAG) functionality:

    1. **Search Settings**: Customize vector and knowledge graph search parameters using `VectorSearchSettings` and `KGSearchSettings`.

    2. **Generation Config**: Fine-tune the language model's behavior with `GenerationConfig`, including:
       * Temperature, top\_p, top\_k for controlling randomness
       * Max tokens, model selection, and streaming options
       * Advanced settings like beam search and sampling strategies

    3. **Multiple LLM Support**: Easily switch between different language models and providers:
       * OpenAI models (default)
       * Anthropic's Claude models
       * Local models via Ollama
       * Any provider supported by LiteLLM

    Example of customizing the model:

    <Tabs>
      <Tab title="Python">
        ```python
        # requires ANTHROPIC_API_KEY is set
        response = client.retrieval.rag(
          "Who was Aristotle?",
          rag_generation_config={"model":"anthropic/claude-3-haiku-20240307", "stream": True}
        )
        for chunk in response:
            print(chunk, flush=False)
        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        await client.rag({
          query: query,
          ragGenerationConfig: {
            model: 'claude-3-haiku-20240307',
            temperature: 0.7,
          }
        });
        ```
      </Tab>

      <Tab title="Curl">
        ```zsh
        # requires ANTHROPIC_API_KEY is set
        curl -X POST https://api.sciphi.ai/v3/retrieval/rag \
            -H "Content-Type: application/json" \
            -d '{
                "query": "Who is Jon Snow?",
                "rag_generation_config": {
                    "model": "claude-3-haiku-20240307",
                    "temperature": 0.7
                }
            }' \
          -H "Authorization: Bearer your_token_here"
        ```
      </Tab>
    </Tabs>

    This flexibility allows you to optimize RAG performance for your specific use case and leverage the strengths of various LLM providers.
  </Accordion>

  <Accordion icon="microscope" title="Streaming Agent (Deep Research Mode)">
    R2R offers a powerful `agentic` retrieval mode that performs in-depth analysis of documents through iterative research and reasoning. This mode can replicate Deep Research-like results by leveraging a variety of tools to thoroughly investigate your data and the web:

    <Tabs>
      <Tab title="Python">
        ```python
        from r2r import (
            ThinkingEvent,
            ToolCallEvent,
            ToolResultEvent,
            CitationEvent,
            FinalAnswerEvent,
            MessageEvent,
            R2RClient,
        )
        client = R2RClient("http://localhost:7272")

        results = client.retrieval.agent(
            message={"role": "user", "content": "What does deepseek r1 imply for the future of AI?"},
            rag_generation_config={
                "model": "anthropic/claude-3-7-sonnet-20250219",
                "extended_thinking": True,
                "thinking_budget": 4096,
                "temperature": 1,
                "top_p": None,
                "max_tokens_to_sample": 16000,
                "stream": True
            },
            mode="research" # for `deep research`, otherwise omit
        )

        # Process the streaming events
        for event in results:
            if isinstance(event, ThinkingEvent):
                print(f"ð§  Thinking: {event.data.delta.content[0].payload.value}")
            elif isinstance(event, ToolCallEvent):
                print(f"ð§ Tool call: {event.data.name}({event.data.arguments})")
            elif isinstance(event, ToolResultEvent):
                print(f"ð Tool result: {event.data.content[:60]}...")
            elif isinstance(event, CitationEvent):
                print(f"ð Citation: {event.data}")
            elif isinstance(event, MessageEvent):
                print(f"ð¬ Message: {event.data.delta.content[0].payload.value}")
            elif isinstance(event, FinalAnswerEvent):
                print(f"â Final answer: {event.data.generated_answer[:100]}...")
                print(f"   Citations: {len(event.data.citations)} sources referenced")



        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        const resultStream = await client.retrieval.agent({
          query: "What does deepseek r1 imply for the future of AI?",
          message: {role: "user", content: "What does deepseek r1 imply for the future of AI?"},
          generationConfig: { stream: true }
          mode: "research" // for `deep research`, otherwise omit
        });

        // Process the streaming events
        if (Symbol.asyncIterator in resultStream) {
          for await (const event of resultStream) {
            switch(event.event) {
              case "thinking":
                console.log(`ð§  Thinking: ${event.data.delta.content[0].payload.value}`);
                break;
              case "tool_call":
                console.log(`ð§ Tool call: ${event.data.name}(${JSON.stringify(event.data.arguments)})`);
                break;
              case "tool_result":
                console.log(`ð Tool result: ${event.data.content.substring(0, 60)}...`);
                break;
              case "citation":
                console.log(`ð Citation event: ${event.data}`);
                break;
              case "message":
                console.log(`ð¬ Message: ${event.data.delta.content[0].payload.value}`);
                break;
              case "final_answer":
                console.log(`â Final answer: ${event.data.generated_answer.substring(0, 100)}...`);
                console.log(`   Citations: ${event.data.citations.length} sources referenced`);
                break;
            }
          }
        }
        ```
      </Tab>
    </Tabs>

    Example of streaming output:

    ```plaintext
    ð§  Thinking: Analyzing the query about DeepSeek R1 implications...
    ð§ Tool call: search_file_knowledge({"query":"DeepSeek R1 capabilities advancements"})
    ð Tool result: DeepSeek-R1 is a reasoning-focused LLM that uses reinforcement learning...
    ð§  Thinking: The search provides valuable information about DeepSeek R1's capabilities
    ð§  Thinking: Need more specific information about its performance in reasoning tasks
    ð§ Tool call: search_file_knowledge({"query":"DeepSeek R1 reasoning benchmarks performance"})
    ð Tool result: DeepSeek-R1 achieves strong results on reasoning benchmarks including MMLU...
    ð Citation: cit_54c45c8
    ð§  Thinking: Now I need to understand the implications for AI development
    ð§ Tool call: web_search({"query":"AI reasoning capabilities future development"})
    ð Tool result: Advanced reasoning capabilities are considered a key milestone toward...
    ð Citation: cit_d1152e7
    ð¬ Message: DeepSeek-R1 has several important implications for the future of AI development:
    ð¬ Message: 1. **Reinforcement Learning as a Key Approach**: DeepSeek-R1's success demonstrates...
    ð Citation: cit_eb5ba04
    ð¬ Message: 2. **Efficiency Through Distillation**: The model shows that reasoning capabilities...
    â Final answer: DeepSeek-R1 has several important implications for the future of AI development: 1. Reinforcement Learning...
      Citations: 3 sources referenced    
    ```
  </Accordion>
</AccordionGroup>

Behind the scenes, R2R's RetrievalService handles RAG requests, combining the power of vector search, optional knowledge graph integration, and language model generation.

## Graphs in R2R

R2R implements a Git-like model for knowledge graphs, where each collection has a corresponding graph that can diverge and be independently managed. This approach allows for flexible knowledge management while maintaining data consistency.

### Graph-Collection Relationship

* Each collection has an associated graph that acts similar to a Git branch
* Graphs can diverge from their underlying collections through independent updates
* The `pull` operation syncs the graph with its collection, similar to a Git pull
* This model enables experimental graph modifications without affecting the base collection

### Knowledge Graph Workflow

<AccordionGroup>
  <Accordion icon="brain" title="Extract Document Knowledge">
    Extract entities and relationships from the previously ingested document:

    <Tabs>
      <Tab title="Python">
        ```python
        client.documents.extract(document_id)
        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        await client.documents.extract(documentId);
        ```
      </Tab>

      <Tab title="Curl">
        ```zsh
        curl -X POST https://api.sciphi.ai/v3/documents/${document_id}/extract \
          -H "Authorization: Bearer your_token_here"
        ```
      </Tab>
    </Tabs>

    This step processes the document to identify entities and their relationships.
  </Accordion>

  <Accordion icon="arrows-rotate" title="Initialize and Populate Graph">
    Sync the graph with the collection and view extracted knowledge:

    <Tabs>
      <Tab title="Python">
        ```python
        collection_id="122fdf6a-e116-546b-a8f6-e4cb2e2c0a09" # default collection_id for admin

        # Sync graph with collection
        pull_response = client.graphs.pull(collection_id)

        # View extracted knowledge
        entities = client.graphs.list_entities(collection_id)
        relationships = client.graphs.list_relationships(collection_id)
        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        // Sync graph with collection
        await client.graphs.pull(collectionId);

        // View extracted knowledge
        const entities = await client.graphs.listEntities(collectionId);
        const relationships = await client.graphs.listRelationships(collectionId);
        ```
      </Tab>

      <Tab title="Curl">
        ```zsh
        # Sync graph with collection
        curl -X POST https://api.sciphi.ai/v3/graphs/${collection_id}/pull \
          -H "Authorization: Bearer your_token_here"

        # View extracted knowledge
        curl -X GET https://api.sciphi.ai/v3/graphs/${collection_id}/entities \
          -H "Authorization: Bearer your_token_here"

        curl -X GET https://api.sciphi.ai/v3/graphs/${collection_id}/relationships \
          -H "Authorization: Bearer your_token_here"

        ```
      </Tab>
    </Tabs>
  </Accordion>

  <Accordion icon="diagram-project" title="Build Graph Communities">
    Build and list graph communities:

    <Tabs>
      <Tab title="Python">
        ```python
        # Build communities
        build_response = client.graphs.build(collection_id, settings={})

        # List communities
        communities = client.graphs.list_communities(collection_id)
        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        // Build communities
        await client.graphs.build(collectionId, {});

        // List communities
        const communities = await client.graphs.listCommunities(collectionId);
        ```
      </Tab>

      <Tab title="Curl">
        ```zsh
        # Build communities
        curl -X POST https://api.sciphi.ai/v3/graphs/${collection_id}/communities/build \
          -H "Content-Type: application/json" \
          -d '{}' \
          -H "Authorization: Bearer your_token_here"

        # List communities
        curl -X GET https://api.sciphi.ai/v3/graphs/${collection_id}/communities \
          -H "Authorization: Bearer your_token_here"
        ```
      </Tab>
    </Tabs>

    ```plaintext
    [
      Community(
        name='Large Language Models and AGI Community', 
        summary='The Large Language Models and AGI Community focuses on the development and implications of advanced AI technologies, particularly in the pursuit of Artificial General Intelligence.', 
        level=None, 
        findings=['Large Language Models (LLMs) are rapidly evolving towards capabilities akin to Artificial General Intelligence (AGI) [Data: Descriptions (1579a46f-be12-4e60-a96b-e5b5afe026d9)].', 'The primary aim of LLMs is to achieve functionalities that closely resemble AGI [Data: Relationships (22bb116d-ab0b-4390-a68f-6ef1a1c99999)].', 'AGI systems are designed to outperform humans in most economically valuable tasks, indicating their potential impact on various industries [Data: Descriptions (80a34efa-d569-488f-91fd-db08fd93667b)].', 'The development of LLMs is a critical step towards realizing the goals of AGI, highlighting the interconnectedness of these technologies [Data: Relationships (22bb116d-ab0b-4390-a68f-6ef1a1c99999)].', 'Research in LLMs is essential for understanding the ethical implications of AGI deployment in society [Data: Descriptions (1579a46f-be12-4e60-a96b-e5b5afe026d9)].'], 
        id=UUID('62fd3478-f303-47ba-941a-fcf41576615d'), 
        community_id=None, 
        collection_id=UUID('122fdf6a-e116-546b-a8f6-e4cb2e2c0a09'), 
        rating=9.0,
        rating_explanation='This community has a significant impact on the future of AI, as it drives research towards achieving AGI capabilities.',
        ...
      ), ...
    ]
    ```
  </Accordion>

  <Accordion icon="magnifying-glass" title="Knowledge Graph Search">
    Perform knowledge graph-enhanced search (enabled by default):

    <Tabs>
      <Tab title="Python">
        ```python
        client.retrieval.search(
            "What was DeepSeek R1"
        )
        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        await client.retrieval.search({
          query: "who was aristotle?",
          graphSearchSettings: {
            useKgSearch: true,
            kgSearchType: "local"
          }
        });
        ```
      </Tab>

      <Tab title="Curl">
        ```zsh
        curl -X POST https://api.sciphi.ai/v3/retrieval/search \
          -H "Content-Type: application/json" \
          -d '{
            "query": "who was aristotle?",
            "graph_search_settings": {
              "use_graph_search": true,
              "kg_search_type": "local"
            }
          }' \
          -H "Authorization: Bearer your_token_here"
        ```
      </Tab>
    </Tabs>
  </Accordion>

  <Accordion icon="trash" title="Cleanup">
    Reset the graph to a clean state:

    <Tabs>
      <Tab title="Python">
        ```python
        client.graphs.reset(collection_id)
        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        await client.graphs.reset(collectionId);
        ```
      </Tab>

      <Tab title="Curl">
        ```zsh
        curl -X POST https://api.sciphi.ai/v3/graphs/${collection_id}/reset \
          -H "Authorization: Bearer your_token_here"
        ```
      </Tab>
    </Tabs>
  </Accordion>
</AccordionGroup>

### Best Practices

1. **Graph Synchronization**
   * Always `pull` before attempting to list or work with entities
   * Keep track of which documents have been added to the graph

2. **Community Management**
   * Build communities after significant changes to the graph
   * Use community information to enhance search results

3. **Version Control**
   * Treat graphs like Git branches - experiment freely
   * Use `reset` to start fresh if needed
   * Maintain documentation of graph modifications

This Git-like model provides a flexible framework for knowledge management while maintaining data consistency and enabling experimental modifications.

## User Management

R2R provides robust user auth and management capabilities. This section briefly covers user authentication features and how they relate to document management.

<AccordionGroup>
  <Accordion icon="user-plus" title="User Registration">
    To register a new user:

    <Tabs>
      <Tab title="Python">
        ```python
        from r2r import R2RClient

        client.users.create("test@example.com", "password123")
        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        await client.users.create("test@gmail.com", "password123")
        ```
      </Tab>

      <Tab title="Curl">
        ```zsh
        curl -X POST https://api.sciphi.ai/v3/users/create \
          -H "Content-Type: application/json" \
          -d '{
            "email": "test@example.com",
            "password": "password123"
          }'
        ```
      </Tab>
    </Tabs>

    Example output:

    ```zsh
    User(
      id=UUID('fcbcbc64-f85c-5025-877c-37f4c7a12d6e'),
      email='test@example.com',
      is_active=True,
      is_superuser=False,
      created_at=datetime.datetime(2025, 2, 8, 5, 8, 17, 376293,
      tzinfo=TzInfo(UTC)),
      updated_at=datetime.datetime(2025, 2, 8, 5, 8, 17, 376293,
      tzinfo=TzInfo(UTC)),
      is_verified=False,
      collection_ids=[UUID('d3ef9c77-cb13-59a9-be70-0db46de619db')],
      graph_ids=[],
      document_ids=[],
      limits_overrides={},
      metadata={},
      verification_code_expiry=None,
      name=None,
      bio=None, 
      rofile_picture=None,
      total_size_in_bytes=None,
      num_files=None,
      account_type='password',
      hashed_password='JDJiJDEyJDE4UFdOTWZTSHNxdzRRMDdKZXU2Nk9qMFNNbXFxVFZldmpHaGhjdTcwdk5hNDZubEMxblVD',
      google_id=None,
      github_id=None
    )
    ```
  </Accordion>

  <Accordion icon="envelope" title="Email Verification">
    After registration, users need to verify their email:

    <Tabs>
      <Tab title="Python">
        ```python
        client.users.verify_email("123456")  # Verification code sent to email
        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        await client.users.verify_email("123456")
        ```
      </Tab>

      <Tab title="Curl">
        ```zsh
        curl -X POST https://api.sciphi.ai/v3/users/verify_email/123456
        ```
      </Tab>
    </Tabs>
  </Accordion>

  <Accordion icon="arrow-right-to-bracket" title="User Login">
    To log in and obtain access tokens:

    <Tabs>
      <Tab title="Python">
        ```python
        client.users.login("test@example.com", "password123")
        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        await client.users.login("test@example.com", "password123")
        ```
      </Tab>

      <Tab title="Curl">
        ```zsh
        curl -X POST https://api.sciphi.ai/v3/users/login \
          -H "Content-Type: application/x-www-form-urlencoded" \
          -d "username=test@example.com&password=password123"
        ```
      </Tab>
    </Tabs>

    ```zsh
    LoginResponse(access_token=Token(token='eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJ0ZXN0QGV4YW1wbGUuY29tIiwidG9rZW5fdHlwZSI6ImFjY2VzcyIsImV4cCI6MTc0MjU5MTQ0Ni43MTY2MzcsImlhdCI6MTczODk5MTQ0Ni43MTY3MDUsIm5iZiI6MTczODk5MTQ0Ni43MTY3MDUsImp0aSI6IkhkWWVfeWxOSm9Yc2tvaU5ZVkdoNHc9PSIsIm5vbmNlIjoiMkhOOUs3bU40QVNfVnkzOTdXR2Vpdz09In0.gG_9oa-7_ZHqfHHo-bE1ooynCm7YCQFCYbJoiEgGmTg', token_type='access'), refresh_token=Token(token='eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJ0ZXN0QGV4YW1wbGUuY29tIiwidG9rZW5fdHlwZSI6InJlZnJlc2giLCJleHAiOjE3Mzk1OTYyNDYuNzE3MzQxLCJpYXQiOjE3Mzg5OTE0NDYuNzE3MzQ5LCJuYmYiOjE3Mzg5OTE0NDYuNzE3MzQ5LCJqdGkiOiJybXltZTk5bGNtZklOWDZLQWNaTmpBPT0iLCJub25jZSI6InExRGdqZm96YkpjYXpDbzdTcE5XcWc9PSJ9.Zn-2pncsEdvyuig36N4APO_U9AWDQcJi6E5EjglN16U', token_type='refresh'))
    ```
  </Accordion>

  <Accordion icon="magnifying-glass" title="User-Specific Search">
    Once authenticated, search results are automatically filtered to include only documents associated with the current user:

    <Tabs>
      <Tab title="Python">
        ```python
        # requires client.users.login(...)
        client.retrieval.search(query="What was DeepSeek R1 about?"
        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        await client.retrieval.search("What was DeepSeek R1 about?")
        ```
      </Tab>

      <Tab title="Curl">
        ```zsh
        curl -X POST https://api.sciphi.ai/v3/retrieval/search \
          -H "Authorization: Bearer YOUR_ACCESS_TOKEN" \
          -H "Content-Type: application/json" \
          -d '{
            "query": "What was DeepSeek R1 about?"
          }'
        ```
      </Tab>
    </Tabs>

    ```zsh
    AggregateSearchResult(chunk_search_results=[], graph_search_results=[], web_search_results=[], context_document_results=[])
    ```
  </Accordion>

  <Accordion icon="arrows-rotate" title="Refresh Access Token">
    To refresh an expired access token:

    <Tabs>
      <Tab title="Python">
        ```python
        # requires client.users.login(...)
        client.users.refresh_access_token()["results"]
        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        await client.refreshAccessToken()
        ```
      </Tab>

      <Tab title="Curl">
        ```zsh
        curl -X POST https://api.sciphi.ai/v3/users/refresh_access_token \
          -H "Authorization: Bearer YOUR_REFRESH_TOKEN" \
          -H "Content-Type: application/json" \
          -d '{
            "refresh_token": "YOUR_REFRESH_TOKEN"
          }'
        ```
      </Tab>
    </Tabs>
  </Accordion>

  <Accordion icon="arrow-right-from-bracket" title="User Logout">
    To log out and invalidate the current access token:

    <Tabs>
      <Tab title="Python">
        ```python
        # requires client.users.login(...)
        client.users.logout()
        ```
      </Tab>

      <Tab title="Curl">
        ```zsh
        curl -X POST https://api.sciphi.ai/v3/users/logout \
          -H "Authorization: Bearer your_token_here"
        ```
      </Tab>

      <Tab title="JavaScript">
        ```javascript
        await client.users.logout()
        ```
      </Tab>
    </Tabs>
  </Accordion>
</AccordionGroup>

These authentication features ensure that users can only access and manage their own documents. When performing operations like search, RAG, or document management, the results are automatically filtered based on the authenticated user's permissions.

Remember to replace `YOUR_ACCESS_TOKEN` and `YOUR_REFRESH_TOKEN` with actual tokens obtained during the login process.

These observability and analytics features provide valuable insights into your R2R application's performance and usage, enabling data-driven optimization and decision-making.

## Next Steps

Now that you have a basic understanding of R2R's core features, you can explore more advanced topics:

* Dive into [document ingestion](/documentation/documents) and [the document reference](/api-and-sdks/documents/documents).
* Learn about [search and RAG](/documentation/hybrid-search) and the [retrieval reference](/api-and-sdks/retrieval/retrieval).
* Try advanced techniques like [knowledge-graphs](/documentation/graphs) and refer to the [graph reference](/api-and-sdks/graphs/graphs).
* Learn about [user authentication](/documentation/user-auth) to secure your application permissions and [the users API reference](/api-and-sdks/users/users).
* Organize your documents using [collections](/api-and-sdks/collections/collections) for granular access control.
